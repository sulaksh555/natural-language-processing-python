{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Synopsis","metadata":{}},{"cell_type":"markdown","source":"This project performs sentiment analysis using natural language processing to detect sarcasm in English news headlines. The data used can be obtained from the URL https://www.kaggle.com/rmisra/news-headlines-dataset-for-sarcasm-detection. The news headlines were converted to sequences of tokens and padded to a uniform length. A recurrent neural network model with long short-term memory was trained on the training set and validated against the validation set. The final out-of-sample accuracy of the natural language processing model was then reported on the test set.","metadata":{}},{"cell_type":"markdown","source":"# Setup","metadata":{}},{"cell_type":"markdown","source":"Import the libraries and methods needed for the project.","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nimport json","metadata":{"execution":{"iopub.status.busy":"2021-10-06T01:47:29.433903Z","iopub.execute_input":"2021-10-06T01:47:29.434742Z","iopub.status.idle":"2021-10-06T01:47:31.182938Z","shell.execute_reply.started":"2021-10-06T01:47:29.434653Z","shell.execute_reply":"2021-10-06T01:47:31.182125Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# Load the Data","metadata":{}},{"cell_type":"markdown","source":"Load the text corpus from the JSON file containing the dataset.","metadata":{}},{"cell_type":"code","source":"def parse_data(file):\n    for l in open(file, \"r\"):\n        yield json.loads(l)\n\ncorpus = list(parse_data(\"../input/news-headlines-dataset-for-sarcasm-detection/Sarcasm_Headlines_Dataset.json\"))","metadata":{"execution":{"iopub.status.busy":"2021-10-06T01:47:57.132623Z","iopub.execute_input":"2021-10-06T01:47:57.132923Z","iopub.status.idle":"2021-10-06T01:47:57.276526Z","shell.execute_reply.started":"2021-10-06T01:47:57.132888Z","shell.execute_reply":"2021-10-06T01:47:57.275818Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"Instantiate lists to store the desired variables of the dataset.","metadata":{}},{"cell_type":"code","source":"sentences = []\nlabels = []","metadata":{"execution":{"iopub.status.busy":"2021-10-06T01:48:01.289046Z","iopub.execute_input":"2021-10-06T01:48:01.289612Z","iopub.status.idle":"2021-10-06T01:48:01.293971Z","shell.execute_reply.started":"2021-10-06T01:48:01.289577Z","shell.execute_reply":"2021-10-06T01:48:01.292767Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"Fill the lists with the corresponding data in the JSON object.","metadata":{}},{"cell_type":"code","source":"for item in corpus:\n    sentences.append(item[\"headline\"])\n    labels.append(item[\"is_sarcastic\"])","metadata":{"execution":{"iopub.status.busy":"2021-10-06T01:48:04.700379Z","iopub.execute_input":"2021-10-06T01:48:04.700660Z","iopub.status.idle":"2021-10-06T01:48:04.716952Z","shell.execute_reply.started":"2021-10-06T01:48:04.700631Z","shell.execute_reply":"2021-10-06T01:48:04.716109Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# Data Partitioning","metadata":{}},{"cell_type":"markdown","source":"Obtain the total number of sentences in the dataset.","metadata":{}},{"cell_type":"code","source":"n_sentences = len(sentences)","metadata":{"execution":{"iopub.status.busy":"2021-10-06T01:48:09.631605Z","iopub.execute_input":"2021-10-06T01:48:09.632107Z","iopub.status.idle":"2021-10-06T01:48:09.638501Z","shell.execute_reply.started":"2021-10-06T01:48:09.632071Z","shell.execute_reply":"2021-10-06T01:48:09.637728Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"Partition the data into a training set, a validation set and a test set. An 80-10-10 split is carried out.","metadata":{}},{"cell_type":"code","source":"training_last_index = int(0.8 * n_sentences)\nvalidation_last_index = int(0.9 * n_sentences)\n\ntraining_sentences = sentences[0 : training_last_index]\nvalidation_sentences = sentences[training_last_index : validation_last_index]\ntest_sentences = sentences[validation_last_index : ]\n\ntraining_labels = labels[0 : training_last_index]\nvalidation_labels = labels[training_last_index : validation_last_index]\ntest_labels = labels[validation_last_index : ]","metadata":{"execution":{"iopub.status.busy":"2021-10-06T01:48:17.656183Z","iopub.execute_input":"2021-10-06T01:48:17.656457Z","iopub.status.idle":"2021-10-06T01:48:17.665770Z","shell.execute_reply.started":"2021-10-06T01:48:17.656428Z","shell.execute_reply":"2021-10-06T01:48:17.664947Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"# Tokenization","metadata":{}},{"cell_type":"markdown","source":"Set hyperparameters for tokenization.","metadata":{}},{"cell_type":"code","source":"vocab_size = 10000\n# Set the maximum length of padded sequences equal to the number of words in the longest training sentence\nmax_length = max([len(training_sentence.split(\" \")) for training_sentence in training_sentences])\noov_token = \"<OOV>\"\npadding_type = \"post\"\ntrunc_type = \"post\"","metadata":{"execution":{"iopub.status.busy":"2021-10-06T01:48:23.424508Z","iopub.execute_input":"2021-10-06T01:48:23.425327Z","iopub.status.idle":"2021-10-06T01:48:23.447063Z","shell.execute_reply.started":"2021-10-06T01:48:23.425291Z","shell.execute_reply":"2021-10-06T01:48:23.446155Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"Instantiate the tokenizer.","metadata":{}},{"cell_type":"code","source":"tokenizer = Tokenizer(num_words = vocab_size,\n                      oov_token = oov_token)","metadata":{"execution":{"iopub.status.busy":"2021-10-06T01:48:28.582261Z","iopub.execute_input":"2021-10-06T01:48:28.582535Z","iopub.status.idle":"2021-10-06T01:48:28.586422Z","shell.execute_reply.started":"2021-10-06T01:48:28.582505Z","shell.execute_reply":"2021-10-06T01:48:28.585712Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"Fit the tokenizer to the training sentences.","metadata":{}},{"cell_type":"code","source":"tokenizer.fit_on_texts(training_sentences)","metadata":{"execution":{"iopub.status.busy":"2021-10-06T01:48:33.446307Z","iopub.execute_input":"2021-10-06T01:48:33.446847Z","iopub.status.idle":"2021-10-06T01:48:33.797078Z","shell.execute_reply.started":"2021-10-06T01:48:33.446813Z","shell.execute_reply":"2021-10-06T01:48:33.796330Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"Obtain the word index of the tokenizer.","metadata":{}},{"cell_type":"code","source":"word_index = tokenizer.word_index","metadata":{"execution":{"iopub.status.busy":"2021-10-06T01:48:37.681527Z","iopub.execute_input":"2021-10-06T01:48:37.682343Z","iopub.status.idle":"2021-10-06T01:48:37.687053Z","shell.execute_reply.started":"2021-10-06T01:48:37.682296Z","shell.execute_reply":"2021-10-06T01:48:37.686195Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"Create sequences of tokens representing the sentences.","metadata":{}},{"cell_type":"code","source":"training_sequences = tokenizer.texts_to_sequences(training_sentences)\nvalidation_sequences = tokenizer.texts_to_sequences(validation_sentences)\ntest_sequences = tokenizer.texts_to_sequences(test_sentences)","metadata":{"execution":{"iopub.status.busy":"2021-10-06T01:48:42.501085Z","iopub.execute_input":"2021-10-06T01:48:42.501986Z","iopub.status.idle":"2021-10-06T01:48:42.837344Z","shell.execute_reply.started":"2021-10-06T01:48:42.501937Z","shell.execute_reply":"2021-10-06T01:48:42.836366Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"Pad the sequences to ensure they're all the same length.","metadata":{}},{"cell_type":"code","source":"training_padded = pad_sequences(training_sequences,\n                                maxlen = max_length,\n                                padding = padding_type,\n                                truncating = trunc_type)\nvalidation_padded = pad_sequences(validation_sequences,\n                                  maxlen = max_length,\n                                  padding = padding_type,\n                                  truncating = trunc_type)\ntest_padded = pad_sequences(test_sequences,\n                            maxlen = max_length,\n                            padding = padding_type,\n                            truncating = trunc_type)","metadata":{"execution":{"iopub.status.busy":"2021-10-06T01:48:47.955471Z","iopub.execute_input":"2021-10-06T01:48:47.955779Z","iopub.status.idle":"2021-10-06T01:48:48.140509Z","shell.execute_reply.started":"2021-10-06T01:48:47.955730Z","shell.execute_reply":"2021-10-06T01:48:48.139746Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"Convert the lists containing the padded sequences and labels to numpy arrays to ensure they're compatible with TensorFlow.","metadata":{}},{"cell_type":"code","source":"training_padded = np.array(training_padded)\ntraining_labels = np.array(training_labels)\n\nvalidation_padded = np.array(validation_padded)\nvalidation_labels = np.array(validation_labels)\n\ntest_padded = np.array(test_padded)\ntest_labels = np.array(test_labels)","metadata":{"execution":{"iopub.status.busy":"2021-10-06T01:48:53.370774Z","iopub.execute_input":"2021-10-06T01:48:53.371394Z","iopub.status.idle":"2021-10-06T01:48:53.384500Z","shell.execute_reply.started":"2021-10-06T01:48:53.371357Z","shell.execute_reply":"2021-10-06T01:48:53.383720Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"# Sanity Check","metadata":{}},{"cell_type":"markdown","source":"Observe the first 10 elements of the word index of the tokenizer.","metadata":{}},{"cell_type":"code","source":"for i, (word, index) in enumerate(word_index.items()):\n    if i < 10:\n        print(f\"{word}: {index}\")","metadata":{"execution":{"iopub.status.busy":"2021-10-06T01:48:59.001750Z","iopub.execute_input":"2021-10-06T01:48:59.002459Z","iopub.status.idle":"2021-10-06T01:48:59.015605Z","shell.execute_reply.started":"2021-10-06T01:48:59.002423Z","shell.execute_reply":"2021-10-06T01:48:59.014850Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"Observe the raw sequence created from the first training sentence.","metadata":{}},{"cell_type":"code","source":"training_sequences[0]","metadata":{"execution":{"iopub.status.busy":"2021-10-06T01:49:05.328283Z","iopub.execute_input":"2021-10-06T01:49:05.329195Z","iopub.status.idle":"2021-10-06T01:49:05.339207Z","shell.execute_reply.started":"2021-10-06T01:49:05.329145Z","shell.execute_reply":"2021-10-06T01:49:05.338475Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"Observe the padded sequence created from the first training sentence.","metadata":{}},{"cell_type":"code","source":"training_padded[0]","metadata":{"execution":{"iopub.status.busy":"2021-10-06T01:49:09.473186Z","iopub.execute_input":"2021-10-06T01:49:09.473466Z","iopub.status.idle":"2021-10-06T01:49:09.478737Z","shell.execute_reply.started":"2021-10-06T01:49:09.473436Z","shell.execute_reply":"2021-10-06T01:49:09.478083Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"Observe the shape of the object containing the padded sequences for the training set.","metadata":{}},{"cell_type":"code","source":"training_padded.shape","metadata":{"execution":{"iopub.status.busy":"2021-10-06T01:49:15.888626Z","iopub.execute_input":"2021-10-06T01:49:15.889221Z","iopub.status.idle":"2021-10-06T01:49:15.894922Z","shell.execute_reply.started":"2021-10-06T01:49:15.889182Z","shell.execute_reply":"2021-10-06T01:49:15.893950Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"It is observed that there are 21367 sequences in the training set, each sequence having a length of 39.","metadata":{}},{"cell_type":"markdown","source":"# Define the Model","metadata":{}},{"cell_type":"markdown","source":"Set the size of the word embeddings.","metadata":{}},{"cell_type":"code","source":"embedding_dim = 64","metadata":{"execution":{"iopub.status.busy":"2021-10-06T01:49:23.647774Z","iopub.execute_input":"2021-10-06T01:49:23.648770Z","iopub.status.idle":"2021-10-06T01:49:23.652721Z","shell.execute_reply.started":"2021-10-06T01:49:23.648728Z","shell.execute_reply":"2021-10-06T01:49:23.651842Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"Define the layers of the natural language processing model.","metadata":{}},{"cell_type":"code","source":"model = tf.keras.Sequential([\n    tf.keras.layers.Embedding(input_dim = vocab_size,\n                              output_dim = embedding_dim,\n                              input_length = max_length),\n    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(units = 64,\n                                                       return_sequences = True)),\n    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(units = 32)),\n    tf.keras.layers.Dense(units = 64,\n                          activation = \"relu\"),\n    tf.keras.layers.Dense(units = 1, \n                          activation = \"sigmoid\")\n])","metadata":{"execution":{"iopub.status.busy":"2021-10-06T01:49:31.488962Z","iopub.execute_input":"2021-10-06T01:49:31.489539Z","iopub.status.idle":"2021-10-06T01:49:33.735034Z","shell.execute_reply.started":"2021-10-06T01:49:31.489501Z","shell.execute_reply":"2021-10-06T01:49:33.734294Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"Obtain an overview of the model.","metadata":{}},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2021-10-06T01:49:40.323015Z","iopub.execute_input":"2021-10-06T01:49:40.323740Z","iopub.status.idle":"2021-10-06T01:49:40.335980Z","shell.execute_reply.started":"2021-10-06T01:49:40.323703Z","shell.execute_reply":"2021-10-06T01:49:40.335242Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"Compile the model with a loss function, optimizer and metric.","metadata":{}},{"cell_type":"code","source":"model.compile(loss = \"binary_crossentropy\",\n              optimizer = \"adam\",\n              metrics = [\"accuracy\"])","metadata":{"execution":{"iopub.status.busy":"2021-10-06T01:49:48.929049Z","iopub.execute_input":"2021-10-06T01:49:48.929822Z","iopub.status.idle":"2021-10-06T01:49:48.946829Z","shell.execute_reply.started":"2021-10-06T01:49:48.929779Z","shell.execute_reply":"2021-10-06T01:49:48.946018Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"# Train the Model","metadata":{}},{"cell_type":"markdown","source":"Choose a desired number of epochs.","metadata":{}},{"cell_type":"code","source":"n_epochs = 30","metadata":{"execution":{"iopub.status.busy":"2021-10-06T01:49:57.462662Z","iopub.execute_input":"2021-10-06T01:49:57.462960Z","iopub.status.idle":"2021-10-06T01:49:57.467121Z","shell.execute_reply.started":"2021-10-06T01:49:57.462929Z","shell.execute_reply":"2021-10-06T01:49:57.466171Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"Train the model for the given number of epochs.","metadata":{}},{"cell_type":"code","source":"history = model.fit(x = training_padded,\n                    y = training_labels,\n                    epochs = n_epochs,\n                    validation_data = (validation_padded, validation_labels),\n                    verbose = 2)","metadata":{"execution":{"iopub.status.busy":"2021-10-06T01:50:02.661842Z","iopub.execute_input":"2021-10-06T01:50:02.662413Z","iopub.status.idle":"2021-10-06T01:55:14.768800Z","shell.execute_reply.started":"2021-10-06T01:50:02.662377Z","shell.execute_reply":"2021-10-06T01:55:14.768125Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"Create a helper function to plot training and validation curves.","metadata":{}},{"cell_type":"code","source":"def PlotGraphs(history, metric):\n    plt.plot(history.history[metric])\n    plt.plot(history.history[\"val_\" + metric], \"\")\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(metric)\n    plt.legend([metric, \"val_\" + metric])","metadata":{"execution":{"iopub.status.busy":"2021-10-06T02:00:07.376681Z","iopub.execute_input":"2021-10-06T02:00:07.376981Z","iopub.status.idle":"2021-10-06T02:00:07.382390Z","shell.execute_reply.started":"2021-10-06T02:00:07.376951Z","shell.execute_reply":"2021-10-06T02:00:07.381594Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":"Visualize the respective plots.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize = [16, 8])\nplt.subplot(1, 2, 1)\nPlotGraphs(history, \"accuracy\")\nplt.ylim(None, 1)\nplt.subplot(1, 2, 2)\nPlotGraphs(history, \"loss\")\nplt.ylim(0, None)","metadata":{"execution":{"iopub.status.busy":"2021-10-06T02:00:12.436603Z","iopub.execute_input":"2021-10-06T02:00:12.436881Z","iopub.status.idle":"2021-10-06T02:00:12.849093Z","shell.execute_reply.started":"2021-10-06T02:00:12.436836Z","shell.execute_reply":"2021-10-06T02:00:12.848276Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":"# Evaluate the Model","metadata":{}},{"cell_type":"markdown","source":"Perform a final evaluation of the model on the test set.","metadata":{}},{"cell_type":"code","source":"test_loss, test_accuracy = model.evaluate(x = test_padded,\n                                          y = test_labels)\n\nprint(f\"Loss on the test set: {test_loss}\")\nprint(f\"Accuracy on the test set: {test_accuracy}\")","metadata":{"execution":{"iopub.status.busy":"2021-10-06T02:00:20.161247Z","iopub.execute_input":"2021-10-06T02:00:20.161540Z","iopub.status.idle":"2021-10-06T02:00:20.640799Z","shell.execute_reply.started":"2021-10-06T02:00:20.161512Z","shell.execute_reply":"2021-10-06T02:00:20.640154Z"},"trusted":true},"execution_count":26,"outputs":[]}]}

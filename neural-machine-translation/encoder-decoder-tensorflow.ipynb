{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d682f7db",
   "metadata": {
    "papermill": {
     "duration": 0.052749,
     "end_time": "2021-12-17T00:03:55.641066",
     "exception": false,
     "start_time": "2021-12-17T00:03:55.588317",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Synopsis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0900e81b",
   "metadata": {
    "papermill": {
     "duration": 0.049616,
     "end_time": "2021-12-17T00:03:55.743030",
     "exception": false,
     "start_time": "2021-12-17T00:03:55.693414",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This project involved building an encoder-decoder model to translate text from English to Spanish. The model was built using TensorFlow and the dataset was sourced from the website http://www.manythings.org/anki/. The final model was exported for incorporation into a Streamlit web application."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03445200",
   "metadata": {
    "papermill": {
     "duration": 0.049158,
     "end_time": "2021-12-17T00:03:55.842266",
     "exception": false,
     "start_time": "2021-12-17T00:03:55.793108",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa7e3f0",
   "metadata": {
    "papermill": {
     "duration": 0.04917,
     "end_time": "2021-12-17T00:03:55.941636",
     "exception": false,
     "start_time": "2021-12-17T00:03:55.892466",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Import the libraries and methods required for the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4199ddc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T00:03:56.052667Z",
     "iopub.status.busy": "2021-12-17T00:03:56.051902Z",
     "iopub.status.idle": "2021-12-17T00:05:06.951494Z",
     "shell.execute_reply": "2021-12-17T00:05:06.950836Z",
     "shell.execute_reply.started": "2021-12-14T12:32:30.551027Z"
    },
    "papermill": {
     "duration": 70.959617,
     "end_time": "2021-12-17T00:05:06.951639",
     "exception": false,
     "start_time": "2021-12-17T00:03:55.992022",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow_text\r\n",
      "  Downloading tensorflow_text-2.7.3-cp37-cp37m-manylinux2010_x86_64.whl (4.9 MB)\r\n",
      "\u001b[K     |████████████████████████████████| 4.9 MB 524 kB/s \r\n",
      "\u001b[?25hCollecting tensorflow<2.8,>=2.7.0\r\n",
      "  Downloading tensorflow-2.7.0-cp37-cp37m-manylinux2010_x86_64.whl (489.6 MB)\r\n",
      "\u001b[K     |████████████████████████████████| 489.6 MB 20 kB/s \r\n",
      "\u001b[?25hRequirement already satisfied: tensorflow-hub>=0.8.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow_text) (0.12.0)\r\n",
      "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (1.12)\r\n",
      "Requirement already satisfied: numpy>=1.14.5 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (1.19.5)\r\n",
      "Requirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (3.1.0)\r\n",
      "Collecting libclang>=9.0.1\r\n",
      "  Downloading libclang-12.0.0-py2.py3-none-manylinux1_x86_64.whl (13.4 MB)\r\n",
      "\u001b[K     |████████████████████████████████| 13.4 MB 17.2 MB/s \r\n",
      "\u001b[?25hCollecting tensorflow-estimator<2.8,~=2.7.0rc0\r\n",
      "  Downloading tensorflow_estimator-2.7.0-py2.py3-none-any.whl (463 kB)\r\n",
      "\u001b[K     |████████████████████████████████| 463 kB 45.5 MB/s \r\n",
      "\u001b[?25hCollecting keras<2.8,>=2.7.0rc0\r\n",
      "  Downloading keras-2.7.0-py2.py3-none-any.whl (1.3 MB)\r\n",
      "\u001b[K     |████████████████████████████████| 1.3 MB 47.8 MB/s \r\n",
      "\u001b[?25hRequirement already satisfied: absl-py>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (0.14.0)\r\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (1.38.1)\r\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (1.12.1)\r\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (1.16.0)\r\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (3.3.0)\r\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (1.6.3)\r\n",
      "Requirement already satisfied: tensorboard~=2.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (2.6.0)\r\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (1.1.0)\r\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (3.19.0)\r\n",
      "Requirement already satisfied: wheel<1.0,>=0.32.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (0.37.0)\r\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (0.2.0)\r\n",
      "Requirement already satisfied: gast<0.5.0,>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (0.4.0)\r\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.21.0\r\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.23.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.1 MB)\r\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 42.6 MB/s \r\n",
      "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (1.1.2)\r\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (3.10.0.2)\r\n",
      "Requirement already satisfied: cached-property in /opt/conda/lib/python3.7/site-packages (from h5py>=2.9.0->tensorflow<2.8,>=2.7.0->tensorflow_text) (1.5.2)\r\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (1.8.0)\r\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (1.35.0)\r\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (2.25.1)\r\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (58.0.4)\r\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (3.3.4)\r\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (2.0.1)\r\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (0.6.1)\r\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (0.4.6)\r\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (0.2.7)\r\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (4.7.2)\r\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (4.2.2)\r\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (1.3.0)\r\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (4.8.1)\r\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (0.4.8)\r\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (4.0.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (2021.10.8)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (1.26.6)\r\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (2.10)\r\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (3.1.1)\r\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->markdown>=2.6.8->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (3.5.0)\r\n",
      "Installing collected packages: tensorflow-io-gcs-filesystem, tensorflow-estimator, libclang, keras, tensorflow, tensorflow-text\r\n",
      "  Attempting uninstall: tensorflow-estimator\r\n",
      "    Found existing installation: tensorflow-estimator 2.6.0\r\n",
      "    Uninstalling tensorflow-estimator-2.6.0:\r\n",
      "      Successfully uninstalled tensorflow-estimator-2.6.0\r\n",
      "  Attempting uninstall: keras\r\n",
      "    Found existing installation: keras 2.6.0\r\n",
      "    Uninstalling keras-2.6.0:\r\n",
      "      Successfully uninstalled keras-2.6.0\r\n",
      "  Attempting uninstall: tensorflow\r\n",
      "    Found existing installation: tensorflow 2.6.0\r\n",
      "    Uninstalling tensorflow-2.6.0:\r\n",
      "      Successfully uninstalled tensorflow-2.6.0\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "explainable-ai-sdk 1.3.2 requires xai-image-widget, which is not installed.\r\n",
      "tfx-bsl 1.3.0 requires absl-py<0.13,>=0.9, but you have absl-py 0.14.0 which is incompatible.\r\n",
      "tfx-bsl 1.3.0 requires pyarrow<3,>=1, but you have pyarrow 5.0.0 which is incompatible.\r\n",
      "tensorflow-transform 1.3.0 requires absl-py<0.13,>=0.9, but you have absl-py 0.14.0 which is incompatible.\r\n",
      "tensorflow-transform 1.3.0 requires pyarrow<3,>=1, but you have pyarrow 5.0.0 which is incompatible.\r\n",
      "tensorflow-transform 1.3.0 requires tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,<2.7,>=1.15.2, but you have tensorflow 2.7.0 which is incompatible.\r\n",
      "tensorflow-io 0.18.0 requires tensorflow<2.6.0,>=2.5.0, but you have tensorflow 2.7.0 which is incompatible.\r\n",
      "tensorflow-io 0.18.0 requires tensorflow-io-gcs-filesystem==0.18.0, but you have tensorflow-io-gcs-filesystem 0.23.1 which is incompatible.\u001b[0m\r\n",
      "Successfully installed keras-2.7.0 libclang-12.0.0 tensorflow-2.7.0 tensorflow-estimator-2.7.0 tensorflow-io-gcs-filesystem-0.23.1 tensorflow-text-2.7.3\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "! pip install tensorflow_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4826af4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T00:05:07.579005Z",
     "iopub.status.busy": "2021-12-17T00:05:07.578145Z",
     "iopub.status.idle": "2021-12-17T00:05:12.578369Z",
     "shell.execute_reply": "2021-12-17T00:05:12.577846Z",
     "shell.execute_reply.started": "2021-12-14T13:23:40.374312Z"
    },
    "papermill": {
     "duration": 5.361662,
     "end_time": "2021-12-17T00:05:12.578512",
     "exception": false,
     "start_time": "2021-12-17T00:05:07.216850",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "import tensorflow_text as tf_text\n",
    "import random\n",
    "import pathlib\n",
    "import typing\n",
    "from typing import Any, Tuple\n",
    "from nltk.translate.bleu_score import corpus_bleu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493fb367",
   "metadata": {
    "papermill": {
     "duration": 0.272954,
     "end_time": "2021-12-17T00:05:13.129689",
     "exception": false,
     "start_time": "2021-12-17T00:05:12.856735",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Create a shape checker class to ensure that all objects have the right dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc6366e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T00:05:13.699180Z",
     "iopub.status.busy": "2021-12-17T00:05:13.698311Z",
     "iopub.status.idle": "2021-12-17T00:05:13.701014Z",
     "shell.execute_reply": "2021-12-17T00:05:13.700588Z",
     "shell.execute_reply.started": "2021-12-12T04:32:36.870263Z"
    },
    "papermill": {
     "duration": 0.29444,
     "end_time": "2021-12-17T00:05:13.701134",
     "exception": false,
     "start_time": "2021-12-17T00:05:13.406694",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ShapeChecker():\n",
    "    def __init__(self):\n",
    "        # keep a cache of every axis-name seen\n",
    "        self.shapes = {}\n",
    "        \n",
    "    def __call__(self,\n",
    "                 tensor, \n",
    "                 names,\n",
    "                 broadcast = False):\n",
    "        if not tf.executing_eagerly():\n",
    "            return\n",
    "        \n",
    "        if isinstance(names, str):\n",
    "            names = (names, )\n",
    "            \n",
    "        shape = tf.shape(tensor)\n",
    "        rank = tf.rank(tensor)\n",
    "        \n",
    "        if rank != len(names):\n",
    "            raise ValueError(f\"Rank mismatch:\\n\"\n",
    "                             f\"   Found {rank}: {shape.numpy()}\\n\"\n",
    "                             f\"   Expected {len(names)}: {names}\\n\")\n",
    "            \n",
    "        for i, name in enumerate(names):\n",
    "            if isinstance(name, int):\n",
    "                old_dim = name\n",
    "            else:\n",
    "                old_dim = self.shapes.get(name, None)\n",
    "            new_dim = shape[i]\n",
    "            \n",
    "            if (broadcast and new_dim == 1):\n",
    "                continue\n",
    "                \n",
    "            if old_dim is None:\n",
    "                # if the axis name is new, add its length to the cache\n",
    "                self.shapes[name] = new_dim\n",
    "                continue\n",
    "                \n",
    "            if new_dim != old_dim:\n",
    "                raise ValueError(f\"Shape mismatch for dimension: '{name}'\\n\"\n",
    "                                 f\"   Found: {new_dim}\\n\"\n",
    "                                 f\"   Expected: {old_dim}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81225c3",
   "metadata": {
    "papermill": {
     "duration": 0.275533,
     "end_time": "2021-12-17T00:05:14.248120",
     "exception": false,
     "start_time": "2021-12-17T00:05:13.972587",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# The data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c62ec90",
   "metadata": {
    "papermill": {
     "duration": 0.272067,
     "end_time": "2021-12-17T00:05:14.807740",
     "exception": false,
     "start_time": "2021-12-17T00:05:14.535673",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6f39f7",
   "metadata": {
    "papermill": {
     "duration": 0.257889,
     "end_time": "2021-12-17T00:05:15.324724",
     "exception": false,
     "start_time": "2021-12-17T00:05:15.066835",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Load the Spanish-to-English dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d130dccc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T00:05:16.097841Z",
     "iopub.status.busy": "2021-12-17T00:05:16.096900Z",
     "iopub.status.idle": "2021-12-17T00:05:16.408975Z",
     "shell.execute_reply": "2021-12-17T00:05:16.407883Z",
     "shell.execute_reply.started": "2021-12-14T12:37:08.268799Z"
    },
    "papermill": {
     "duration": 0.740973,
     "end_time": "2021-12-17T00:05:16.409112",
     "exception": false,
     "start_time": "2021-12-17T00:05:15.668139",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\n",
      "2646016/2638744 [==============================] - 0s 0us/step\n",
      "2654208/2638744 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "path_to_zip = tf.keras.utils.get_file(\"spa-eng.zip\",\n",
    "                                      origin = \"http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\",\n",
    "                                      extract = True)\n",
    "path_to_file = pathlib.Path(path_to_zip).parent/\"spa-eng/spa.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89ff86d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T00:05:16.949766Z",
     "iopub.status.busy": "2021-12-17T00:05:16.948957Z",
     "iopub.status.idle": "2021-12-17T00:05:16.952394Z",
     "shell.execute_reply": "2021-12-17T00:05:16.951945Z",
     "shell.execute_reply.started": "2021-12-14T12:37:12.312115Z"
    },
    "papermill": {
     "duration": 0.271956,
     "end_time": "2021-12-17T00:05:16.952519",
     "exception": false,
     "start_time": "2021-12-17T00:05:16.680563",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    text = path.read_text(encoding = \"utf-8\")\n",
    "    \n",
    "    lines = text.splitlines()\n",
    "    pairs = [line.split(\"\\t\") for line in lines]\n",
    "    \n",
    "    inp = [inp for inp, targ in pairs]\n",
    "    targ = [targ for inp, targ in pairs]\n",
    "    \n",
    "    return inp, targ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "375d7592",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T00:05:17.474206Z",
     "iopub.status.busy": "2021-12-17T00:05:17.473075Z",
     "iopub.status.idle": "2021-12-17T00:05:17.819033Z",
     "shell.execute_reply": "2021-12-17T00:05:17.818475Z",
     "shell.execute_reply.started": "2021-12-14T12:37:16.280881Z"
    },
    "papermill": {
     "duration": 0.611237,
     "end_time": "2021-12-17T00:05:17.819162",
     "exception": false,
     "start_time": "2021-12-17T00:05:17.207925",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "inp, targ = load_data(path_to_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4b4117",
   "metadata": {
    "papermill": {
     "duration": 0.320826,
     "end_time": "2021-12-17T00:05:18.397901",
     "exception": false,
     "start_time": "2021-12-17T00:05:18.077075",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Training the model on the full dataset will take a very long time. Subset a desired number of examples from the original dataset to train the model on within a reasonable amount of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0aa71a9a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T00:05:18.923498Z",
     "iopub.status.busy": "2021-12-17T00:05:18.922665Z",
     "iopub.status.idle": "2021-12-17T00:05:18.925713Z",
     "shell.execute_reply": "2021-12-17T00:05:18.926117Z",
     "shell.execute_reply.started": "2021-12-14T12:37:20.499886Z"
    },
    "papermill": {
     "duration": 0.267633,
     "end_time": "2021-12-17T00:05:18.926271",
     "exception": false,
     "start_time": "2021-12-17T00:05:18.658638",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples in the full dataset: 118964\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of examples in the full dataset: {len(inp)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f89d659",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T00:05:19.447084Z",
     "iopub.status.busy": "2021-12-17T00:05:19.446202Z",
     "iopub.status.idle": "2021-12-17T00:05:19.449656Z",
     "shell.execute_reply": "2021-12-17T00:05:19.449205Z",
     "shell.execute_reply.started": "2021-12-14T12:37:23.995287Z"
    },
    "papermill": {
     "duration": 0.266898,
     "end_time": "2021-12-17T00:05:19.449778",
     "exception": false,
     "start_time": "2021-12-17T00:05:19.182880",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_desired_examples = 50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d0fba85",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T00:05:19.982846Z",
     "iopub.status.busy": "2021-12-17T00:05:19.982056Z",
     "iopub.status.idle": "2021-12-17T00:05:19.984924Z",
     "shell.execute_reply": "2021-12-17T00:05:19.984482Z",
     "shell.execute_reply.started": "2021-12-14T12:37:27.693739Z"
    },
    "papermill": {
     "duration": 0.277963,
     "end_time": "2021-12-17T00:05:19.985045",
     "exception": false,
     "start_time": "2021-12-17T00:05:19.707082",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "inp = inp[0:n_desired_examples]\n",
    "targ = targ[0:n_desired_examples]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ceec5b3",
   "metadata": {
    "papermill": {
     "duration": 0.259009,
     "end_time": "2021-12-17T00:05:20.502286",
     "exception": false,
     "start_time": "2021-12-17T00:05:20.243277",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Data partitioning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8c33ae",
   "metadata": {
    "papermill": {
     "duration": 0.258115,
     "end_time": "2021-12-17T00:05:21.018329",
     "exception": false,
     "start_time": "2021-12-17T00:05:20.760214",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Carve out a training set and a test set from the original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d346b847",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T00:05:21.570540Z",
     "iopub.status.busy": "2021-12-17T00:05:21.555157Z",
     "iopub.status.idle": "2021-12-17T00:05:43.904628Z",
     "shell.execute_reply": "2021-12-17T00:05:43.904051Z"
    },
    "papermill": {
     "duration": 22.629718,
     "end_time": "2021-12-17T00:05:43.904778",
     "exception": false,
     "start_time": "2021-12-17T00:05:21.275060",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "original_indices = list(range(n_desired_examples))\n",
    "train_size = int(0.9 * n_desired_examples)\n",
    "train_indices = random.sample(original_indices, train_size)\n",
    "test_indices = [index for index in original_indices if (index not in train_indices)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c57b519",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T00:05:44.454714Z",
     "iopub.status.busy": "2021-12-17T00:05:44.453399Z",
     "iopub.status.idle": "2021-12-17T00:05:44.456813Z",
     "shell.execute_reply": "2021-12-17T00:05:44.457208Z"
    },
    "papermill": {
     "duration": 0.292479,
     "end_time": "2021-12-17T00:05:44.457367",
     "exception": false,
     "start_time": "2021-12-17T00:05:44.164888",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_inputs = [inp[i] for i in train_indices]\n",
    "test_inputs = [inp[i] for i in test_indices]\n",
    "train_targets = [targ[i] for i in train_indices]\n",
    "test_targets = [targ[i] for i in test_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5bc0b9",
   "metadata": {
    "papermill": {
     "duration": 0.258617,
     "end_time": "2021-12-17T00:05:44.978478",
     "exception": false,
     "start_time": "2021-12-17T00:05:44.719861",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Create a tf.data dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e48225c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T00:05:45.506883Z",
     "iopub.status.busy": "2021-12-17T00:05:45.505940Z",
     "iopub.status.idle": "2021-12-17T00:05:45.507720Z",
     "shell.execute_reply": "2021-12-17T00:05:45.508357Z",
     "shell.execute_reply.started": "2021-12-12T04:33:16.683761Z"
    },
    "papermill": {
     "duration": 0.269085,
     "end_time": "2021-12-17T00:05:45.508534",
     "exception": false,
     "start_time": "2021-12-17T00:05:45.239449",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "BUFFER_SIZE = len(train_inputs)\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b4f6c435",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T00:05:46.080424Z",
     "iopub.status.busy": "2021-12-17T00:05:46.060185Z",
     "iopub.status.idle": "2021-12-17T00:05:46.532157Z",
     "shell.execute_reply": "2021-12-17T00:05:46.532960Z",
     "shell.execute_reply.started": "2021-12-12T04:33:20.249768Z"
    },
    "papermill": {
     "duration": 0.750944,
     "end_time": "2021-12-17T00:05:46.533162",
     "exception": false,
     "start_time": "2021-12-17T00:05:45.782218",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-17 00:05:46.312091: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda/lib:/usr/local/lib/x86_64-linux-gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2021-12-17 00:05:46.327914: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((train_inputs, train_targets)).shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185e2e3e",
   "metadata": {
    "papermill": {
     "duration": 0.262135,
     "end_time": "2021-12-17T00:05:47.064101",
     "exception": false,
     "start_time": "2021-12-17T00:05:46.801966",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Create the translator template"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0857fcb3",
   "metadata": {
    "papermill": {
     "duration": 0.264947,
     "end_time": "2021-12-17T00:05:47.590796",
     "exception": false,
     "start_time": "2021-12-17T00:05:47.325849",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Text standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a1e1d9db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T00:05:48.120844Z",
     "iopub.status.busy": "2021-12-17T00:05:48.119965Z",
     "iopub.status.idle": "2021-12-17T00:05:48.121830Z",
     "shell.execute_reply": "2021-12-17T00:05:48.122246Z",
     "shell.execute_reply.started": "2021-12-12T04:33:31.796999Z"
    },
    "papermill": {
     "duration": 0.270263,
     "end_time": "2021-12-17T00:05:48.122398",
     "exception": false,
     "start_time": "2021-12-17T00:05:47.852135",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tf_lower_and_split_punct(text):\n",
    "    # split accented characters\n",
    "    text = tf_text.normalize_utf8(text,\n",
    "                                  \"NFKD\")\n",
    "    text = tf.strings.lower(text)\n",
    "    \n",
    "    # keep spaces, a-z, and select punctuation\n",
    "    text = tf.strings.regex_replace(text,\n",
    "                                    \"[^ a-z.?!,¿]\",\n",
    "                                    \"\")\n",
    "    \n",
    "    # add spaces around punctuation\n",
    "    text = tf.strings.regex_replace(text,\n",
    "                                    \"[.?!,¿]\",\n",
    "                                    r\" \\0 \")\n",
    "    \n",
    "    # strip whitespace\n",
    "    text = tf.strings.strip(text)\n",
    "    \n",
    "    text = tf.strings.join([\"[START]\", text, \"[END]\"],\n",
    "                           separator = \" \")\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2702ebdb",
   "metadata": {
    "papermill": {
     "duration": 0.40768,
     "end_time": "2021-12-17T00:05:48.788676",
     "exception": false,
     "start_time": "2021-12-17T00:05:48.380996",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## The encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a316532",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T00:05:49.503629Z",
     "iopub.status.busy": "2021-12-17T00:05:49.502970Z",
     "iopub.status.idle": "2021-12-17T00:05:49.506601Z",
     "shell.execute_reply": "2021-12-17T00:05:49.507156Z",
     "shell.execute_reply.started": "2021-12-12T04:33:37.764516Z"
    },
    "papermill": {
     "duration": 0.349492,
     "end_time": "2021-12-17T00:05:49.507359",
     "exception": false,
     "start_time": "2021-12-17T00:05:49.157867",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, \n",
    "                 input_vocab_size,\n",
    "                 embedding_dim,\n",
    "                 enc_units):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.enc_units = enc_units\n",
    "        self.input_vocab_size = input_vocab_size\n",
    "        \n",
    "        # the embedding layer converts tokens to vectors\n",
    "        self.embedding = tf.keras.layers.Embedding(input_dim = self.input_vocab_size,\n",
    "                                                   output_dim = embedding_dim)\n",
    "        \n",
    "        # the GRU RNN layer processes those vectors sequentially\n",
    "        self.gru = tf.keras.layers.GRU(self.enc_units,\n",
    "                                       # return the sequence and state\n",
    "                                       return_sequences = True,\n",
    "                                       return_state = True,\n",
    "                                       recurrent_initializer = \"glorot_uniform\")\n",
    "        \n",
    "    def call(self,\n",
    "             tokens, \n",
    "             state = None):\n",
    "        shape_checker = ShapeChecker()\n",
    "        shape_checker(tokens, (\"batch\", \"s\"))\n",
    "        \n",
    "        # the embedding layer looks up the embedding for each token\n",
    "        vectors = self.embedding(tokens)\n",
    "        shape_checker(vectors, (\"batch\", \"s\", \"embed_dim\"))\n",
    "        \n",
    "        # the GRU processes the embedding sequence\n",
    "        # output shape: (batch, s, enc_units)\n",
    "        # state shape: (batch, enc_units)\n",
    "        output, state = self.gru(vectors,\n",
    "                                 initial_state = state)\n",
    "        shape_checker(output, (\"batch\", \"s\", \"enc_units\"))\n",
    "        shape_checker(state, (\"batch\", \"enc_units\"))\n",
    "        \n",
    "        # returns the new sequence and its state\n",
    "        return output, state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f32f2a",
   "metadata": {
    "papermill": {
     "duration": 0.259069,
     "end_time": "2021-12-17T00:05:50.027873",
     "exception": false,
     "start_time": "2021-12-17T00:05:49.768804",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## The attention head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "86f2346c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T00:05:50.565117Z",
     "iopub.status.busy": "2021-12-17T00:05:50.563505Z",
     "iopub.status.idle": "2021-12-17T00:05:50.565712Z",
     "shell.execute_reply": "2021-12-17T00:05:50.566119Z",
     "shell.execute_reply.started": "2021-12-12T04:33:43.380966Z"
    },
    "papermill": {
     "duration": 0.275737,
     "end_time": "2021-12-17T00:05:50.566280",
     "exception": false,
     "start_time": "2021-12-17T00:05:50.290543",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BahdanauAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self,\n",
    "                 units):\n",
    "        super().__init__()\n",
    "        \n",
    "        # the attention scoring function in Bahdanau's additive style\n",
    "        self.W1 = tf.keras.layers.Dense(units, \n",
    "                                        use_bias = False)\n",
    "        self.W2 = tf.keras.layers.Dense(units,\n",
    "                                        use_bias = False)\n",
    "        \n",
    "        self.attention = tf.keras.layers.AdditiveAttention()\n",
    "        \n",
    "    def call(self,\n",
    "             query,\n",
    "             value, \n",
    "             mask):\n",
    "        shape_checker = ShapeChecker()\n",
    "        shape_checker(query, (\"batch\", \"t\", \"query_units\"))\n",
    "        shape_checker(value, (\"batch\", \"s\", \"value_units\"))\n",
    "        shape_checker(mask, (\"batch\", \"s\"))\n",
    "        \n",
    "        # the W1@ht term in the attention score formula\n",
    "        w1_query = self.W1(query)\n",
    "        shape_checker(w1_query, (\"batch\", \"t\", \"attn_units\"))\n",
    "        \n",
    "        # the W2@hs term in the attention score formula\n",
    "        w2_key = self.W2(value)\n",
    "        shape_checker(w2_key, (\"batch\", \"s\", \"attn_units\"))\n",
    "        \n",
    "        query_mask = tf.ones(tf.shape(query)[:-1],\n",
    "                             dtype = bool)\n",
    "        value_mask = mask\n",
    "        \n",
    "        context_vector, attention_weights = self.attention(inputs = [w1_query, value, w2_key],\n",
    "                                                           mask = [query_mask, value_mask],\n",
    "                                                           return_attention_scores = True)\n",
    "        shape_checker(context_vector, (\"batch\", \"t\", \"value_units\"))\n",
    "        shape_checker(attention_weights, (\"batch\", \"t\", \"s\"))\n",
    "        \n",
    "        return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da69c1c",
   "metadata": {
    "papermill": {
     "duration": 0.2686,
     "end_time": "2021-12-17T00:05:51.096633",
     "exception": false,
     "start_time": "2021-12-17T00:05:50.828033",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## The decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4b8dbaad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T00:05:51.641495Z",
     "iopub.status.busy": "2021-12-17T00:05:51.640703Z",
     "iopub.status.idle": "2021-12-17T00:05:51.642947Z",
     "shell.execute_reply": "2021-12-17T00:05:51.643367Z",
     "shell.execute_reply.started": "2021-12-12T04:33:49.099386Z"
    },
    "papermill": {
     "duration": 0.284332,
     "end_time": "2021-12-17T00:05:51.643521",
     "exception": false,
     "start_time": "2021-12-17T00:05:51.359189",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "    def __init__(self,\n",
    "                 output_vocab_size, \n",
    "                 embedding_dim,\n",
    "                 dec_units):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.dec_units = dec_units\n",
    "        self.output_vocab_size = output_vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        \n",
    "        # step 1 - the embedding layer converts token IDs to vectors\n",
    "        self.embedding = tf.keras.layers.Embedding(input_dim = self.output_vocab_size,\n",
    "                                                   output_dim = embedding_dim)\n",
    "        \n",
    "        # step 2 - the RNN keeps track of what's been generated so far\n",
    "        self.gru = tf.keras.layers.GRU(self.dec_units,\n",
    "                                       return_sequences = True,\n",
    "                                       return_state = True,\n",
    "                                       recurrent_initializer = \"glorot_uniform\")\n",
    "        \n",
    "        # step 3 - the RNN output will be the query for the attention layer\n",
    "        self.attention = BahdanauAttention(self.dec_units)\n",
    "        \n",
    "        # step 4 - converting the context vector to the attention vector\n",
    "        self.Wc = tf.keras.layers.Dense(dec_units,\n",
    "                                        activation = tf.math.tanh,\n",
    "                                        use_bias = False)\n",
    "        \n",
    "        # step 5 - this fully connected layer produces the logits for each output token\n",
    "        self.fc = tf.keras.layers.Dense(self.output_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e4ba9b57",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T00:05:52.165591Z",
     "iopub.status.busy": "2021-12-17T00:05:52.164073Z",
     "iopub.status.idle": "2021-12-17T00:05:52.170273Z",
     "shell.execute_reply": "2021-12-17T00:05:52.169827Z",
     "shell.execute_reply.started": "2021-12-12T04:33:54.215723Z"
    },
    "papermill": {
     "duration": 0.270483,
     "end_time": "2021-12-17T00:05:52.170401",
     "exception": false,
     "start_time": "2021-12-17T00:05:51.899918",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DecoderInput(typing.NamedTuple):\n",
    "    new_tokens: Any\n",
    "    enc_output: Any\n",
    "    mask: Any\n",
    "\n",
    "class DecoderOutput(typing.NamedTuple):\n",
    "    logits: Any\n",
    "    attention_weights: Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b7242f5b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T00:05:52.709287Z",
     "iopub.status.busy": "2021-12-17T00:05:52.707657Z",
     "iopub.status.idle": "2021-12-17T00:05:52.709878Z",
     "shell.execute_reply": "2021-12-17T00:05:52.710313Z",
     "shell.execute_reply.started": "2021-12-12T04:33:57.810663Z"
    },
    "papermill": {
     "duration": 0.27927,
     "end_time": "2021-12-17T00:05:52.710461",
     "exception": false,
     "start_time": "2021-12-17T00:05:52.431191",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def call(self,\n",
    "         inputs: DecoderInput,\n",
    "         state = None) -> Tuple[DecoderOutput, tf.Tensor]:\n",
    "    shape_checker = ShapeChecker()\n",
    "    shape_checker(inputs.new_tokens, (\"batch\", \"t\"))\n",
    "    shape_checker(inputs.enc_output, (\"batch\", \"s\", \"enc_units\"))\n",
    "    shape_checker(inputs.mask, (\"batch\", \"s\"))\n",
    "    \n",
    "    if state is not None:\n",
    "        shape_checker(state, (\"batch\", \"dec_units\"))\n",
    "        \n",
    "    # step 1 - lookup the embeddings\n",
    "    vectors = self.embedding(inputs.new_tokens)\n",
    "    shape_checker(vectors, (\"batch\", \"t\", \"embedding_dim\"))\n",
    "    \n",
    "    # step 2 - process one step with the RNN\n",
    "    rnn_output, state = self.gru(vectors,\n",
    "                                 initial_state = state)\n",
    "    \n",
    "    shape_checker(rnn_output, (\"batch\", \"t\", \"dec_units\"))\n",
    "    shape_checker(state, (\"batch\", \"dec_units\"))\n",
    "    \n",
    "    # step 3 - use the RNN output as the query for the attention over the encoder output\n",
    "    context_vector, attention_weights = self.attention(query = rnn_output,\n",
    "                                                       value = inputs.enc_output,\n",
    "                                                       mask = inputs.mask)\n",
    "    shape_checker(context_vector, (\"batch\", \"t\", \"dec_units\"))\n",
    "    shape_checker(attention_weights, (\"batch\", \"t\", \"s\"))\n",
    "    \n",
    "    # step 4 - join the context_vector and rnn_output\n",
    "    # [ct; ht] shape: (batch t, value_units + query_units)\n",
    "    context_and_rnn_output = tf.concat([context_vector, rnn_output],\n",
    "                                       axis = -1)\n",
    "    \n",
    "    # step 4 (continued) - at = tanh(Wc@[ct; ht])\n",
    "    attention_vector = self.Wc(context_and_rnn_output)\n",
    "    shape_checker(attention_vector, (\"batch\", \"t\", \"dec_units\"))\n",
    "    \n",
    "    # step 5 - generate logit predictions\n",
    "    logits = self.fc(attention_vector)\n",
    "    shape_checker(logits, (\"batch\", \"t\", \"output_vocab_size\"))\n",
    "    \n",
    "    return DecoderOutput(logits, attention_weights), state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "80e1f9f0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T00:05:53.236559Z",
     "iopub.status.busy": "2021-12-17T00:05:53.235406Z",
     "iopub.status.idle": "2021-12-17T00:05:53.237275Z",
     "shell.execute_reply": "2021-12-17T00:05:53.237725Z",
     "shell.execute_reply.started": "2021-12-12T04:34:03.452634Z"
    },
    "papermill": {
     "duration": 0.269422,
     "end_time": "2021-12-17T00:05:53.237885",
     "exception": false,
     "start_time": "2021-12-17T00:05:52.968463",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "Decoder.call = call"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d927294a",
   "metadata": {
    "papermill": {
     "duration": 0.258481,
     "end_time": "2021-12-17T00:05:53.752056",
     "exception": false,
     "start_time": "2021-12-17T00:05:53.493575",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a80e215c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T00:05:54.278340Z",
     "iopub.status.busy": "2021-12-17T00:05:54.277368Z",
     "iopub.status.idle": "2021-12-17T00:05:54.279496Z",
     "shell.execute_reply": "2021-12-17T00:05:54.279986Z",
     "shell.execute_reply.started": "2021-12-12T04:34:07.228467Z"
    },
    "papermill": {
     "duration": 0.270194,
     "end_time": "2021-12-17T00:05:54.280143",
     "exception": false,
     "start_time": "2021-12-17T00:05:54.009949",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MaskedLoss(tf.keras.losses.Loss):\n",
    "    def __init__(self):\n",
    "        self.name = \"masked_loss\"\n",
    "        self.loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True,\n",
    "                                                                  reduction = \"none\")\n",
    "        \n",
    "    def __call__(self,\n",
    "                 y_true,\n",
    "                 y_pred):\n",
    "        shape_checker = ShapeChecker()\n",
    "        shape_checker(y_true, (\"batch\", \"t\"))\n",
    "        shape_checker(y_pred, (\"batch\", \"t\", \"logits\"))\n",
    "        \n",
    "        # calculate the loss for each item in the batch\n",
    "        loss = self.loss(y_true,\n",
    "                         y_pred)\n",
    "        shape_checker(loss, (\"batch\", \"t\"))\n",
    "        \n",
    "        # mask off the losses on padding\n",
    "        mask = tf.cast(y_true != 0,\n",
    "                       tf.float32)\n",
    "        shape_checker(mask, (\"batch\", \"t\"))\n",
    "        loss *= mask\n",
    "        \n",
    "        # return the total\n",
    "        return tf.reduce_sum(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c95b3e",
   "metadata": {
    "papermill": {
     "duration": 0.265493,
     "end_time": "2021-12-17T00:05:54.906454",
     "exception": false,
     "start_time": "2021-12-17T00:05:54.640961",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Implementing the training step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6a21c858",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T00:05:55.438634Z",
     "iopub.status.busy": "2021-12-17T00:05:55.437895Z",
     "iopub.status.idle": "2021-12-17T00:05:55.440929Z",
     "shell.execute_reply": "2021-12-17T00:05:55.441340Z",
     "shell.execute_reply.started": "2021-12-12T04:34:13.033106Z"
    },
    "papermill": {
     "duration": 0.273953,
     "end_time": "2021-12-17T00:05:55.441494",
     "exception": false,
     "start_time": "2021-12-17T00:05:55.167541",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TrainTranslator(tf.keras.Model):\n",
    "    def __init__(self,\n",
    "                 embedding_dim,\n",
    "                 units,\n",
    "                 input_text_processor,\n",
    "                 output_text_processor,\n",
    "                 use_tf_function = True):\n",
    "        super().__init__()\n",
    "        \n",
    "        # build the encoder and decoder\n",
    "        encoder = Encoder(input_text_processor.vocabulary_size(),\n",
    "                          embedding_dim,\n",
    "                          units)\n",
    "        decoder = Decoder(output_text_processor.vocabulary_size(),\n",
    "                          embedding_dim,\n",
    "                          units)\n",
    "        \n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.input_text_processor = input_text_processor\n",
    "        self.output_text_processor = output_text_processor\n",
    "        self.use_tf_function = use_tf_function\n",
    "        self.shape_checker = ShapeChecker()\n",
    "        \n",
    "    def train_step(self,\n",
    "                   inputs):\n",
    "        self.shape_checker = ShapeChecker()\n",
    "        if self.use_tf_function:\n",
    "            return self._tf_train_step(inputs)\n",
    "        else:\n",
    "            return self._train_step(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1b5b2aa3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T00:05:55.968678Z",
     "iopub.status.busy": "2021-12-17T00:05:55.967733Z",
     "iopub.status.idle": "2021-12-17T00:05:55.969726Z",
     "shell.execute_reply": "2021-12-17T00:05:55.970111Z",
     "shell.execute_reply.started": "2021-12-12T04:34:18.085748Z"
    },
    "papermill": {
     "duration": 0.271821,
     "end_time": "2021-12-17T00:05:55.970284",
     "exception": false,
     "start_time": "2021-12-17T00:05:55.698463",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def _preprocess(self, \n",
    "                input_text, \n",
    "                target_text):\n",
    "    self.shape_checker(input_text, (\"batch\", ))\n",
    "    self.shape_checker(target_text, (\"batch\", ))\n",
    "    \n",
    "    # convert the text to token IDs\n",
    "    input_tokens = self.input_text_processor(input_text)\n",
    "    target_tokens = self.output_text_processor(target_text)\n",
    "    self.shape_checker(input_tokens, (\"batch\", \"s\"))\n",
    "    self.shape_checker(target_tokens, (\"batch\", \"t\"))\n",
    "\n",
    "    # convert IDs to masks\n",
    "    input_mask = input_tokens != 0\n",
    "    self.shape_checker(input_mask, (\"batch\", \"s\"))\n",
    "\n",
    "    target_mask = target_tokens != 0\n",
    "    self.shape_checker(target_mask, (\"batch\", \"t\"))\n",
    "\n",
    "    return input_tokens, input_mask, target_tokens, target_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d1bf2170",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T00:05:56.514527Z",
     "iopub.status.busy": "2021-12-17T00:05:56.513570Z",
     "iopub.status.idle": "2021-12-17T00:05:56.515218Z",
     "shell.execute_reply": "2021-12-17T00:05:56.515749Z",
     "shell.execute_reply.started": "2021-12-12T04:34:22.118082Z"
    },
    "papermill": {
     "duration": 0.282701,
     "end_time": "2021-12-17T00:05:56.515904",
     "exception": false,
     "start_time": "2021-12-17T00:05:56.233203",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "TrainTranslator._preprocess = _preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "80035dd7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T00:05:57.046512Z",
     "iopub.status.busy": "2021-12-17T00:05:57.044864Z",
     "iopub.status.idle": "2021-12-17T00:05:57.047380Z",
     "shell.execute_reply": "2021-12-17T00:05:57.047802Z",
     "shell.execute_reply.started": "2021-12-12T04:34:25.375591Z"
    },
    "papermill": {
     "duration": 0.27501,
     "end_time": "2021-12-17T00:05:57.047948",
     "exception": false,
     "start_time": "2021-12-17T00:05:56.772938",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def _train_step(self, \n",
    "                inputs):\n",
    "    input_text, target_text = inputs  \n",
    "    (input_tokens, input_mask, target_tokens, target_mask) = self._preprocess(input_text, \n",
    "                                                                              target_text)\n",
    "\n",
    "    max_target_length = tf.shape(target_tokens)[1]\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        # encode the input\n",
    "        enc_output, enc_state = self.encoder(input_tokens)\n",
    "        self.shape_checker(enc_output, (\"batch\", \"s\", \"enc_units\"))\n",
    "        self.shape_checker(enc_state, (\"batch\", \"enc_units\"))\n",
    "\n",
    "        # initialize the decoder's state to the encoder's final state\n",
    "        # this only works if the encoder and decoder have the same number of units\n",
    "        dec_state = enc_state\n",
    "        loss = tf.constant(0.0)\n",
    "\n",
    "        for t in tf.range(max_target_length-1):\n",
    "            # pass in two tokens from the target sequence:\n",
    "            # 1. the current input to the decoder.\n",
    "            # 2. the target for the decoder's next prediction.\n",
    "            new_tokens = target_tokens[:, t:t+2]\n",
    "            step_loss, dec_state = self._loop_step(new_tokens, \n",
    "                                                   input_mask,\n",
    "                                                   enc_output, \n",
    "                                                   dec_state)\n",
    "            loss = loss + step_loss\n",
    "\n",
    "        # average the loss over all non padding tokens.\n",
    "        average_loss = loss / tf.reduce_sum(tf.cast(target_mask, tf.float32))\n",
    "\n",
    "    # apply an optimization step\n",
    "    variables = self.trainable_variables \n",
    "    gradients = tape.gradient(average_loss, variables)\n",
    "    self.optimizer.apply_gradients(zip(gradients, variables))\n",
    "\n",
    "    # return a dict mapping metric names to current value\n",
    "    return {'batch_loss': average_loss}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b6993929",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T00:05:57.578050Z",
     "iopub.status.busy": "2021-12-17T00:05:57.577110Z",
     "iopub.status.idle": "2021-12-17T00:05:57.578715Z",
     "shell.execute_reply": "2021-12-17T00:05:57.579133Z",
     "shell.execute_reply.started": "2021-12-12T04:34:31.015559Z"
    },
    "papermill": {
     "duration": 0.272923,
     "end_time": "2021-12-17T00:05:57.579289",
     "exception": false,
     "start_time": "2021-12-17T00:05:57.306366",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "TrainTranslator._train_step = _train_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "907470d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T00:05:58.114859Z",
     "iopub.status.busy": "2021-12-17T00:05:58.113951Z",
     "iopub.status.idle": "2021-12-17T00:05:58.115787Z",
     "shell.execute_reply": "2021-12-17T00:05:58.116221Z",
     "shell.execute_reply.started": "2021-12-12T04:34:35.701235Z"
    },
    "papermill": {
     "duration": 0.277327,
     "end_time": "2021-12-17T00:05:58.116358",
     "exception": false,
     "start_time": "2021-12-17T00:05:57.839031",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def _loop_step(self, new_tokens, input_mask, enc_output, dec_state):\n",
    "    input_token, target_token = new_tokens[:, 0:1], new_tokens[:, 1:2]\n",
    "\n",
    "    # run the decoder one step\n",
    "    decoder_input = DecoderInput(new_tokens = input_token,\n",
    "                                 enc_output = enc_output,\n",
    "                                 mask = input_mask)\n",
    "\n",
    "    dec_result, dec_state = self.decoder(decoder_input, state = dec_state)\n",
    "    self.shape_checker(dec_result.logits, (\"batch\", \"t1\", \"logits\"))\n",
    "    self.shape_checker(dec_result.attention_weights, (\"batch\", \"t1\", \"s\"))\n",
    "    self.shape_checker(dec_state, (\"batch\", \"dec_units\"))\n",
    "\n",
    "    # 'self.loss' returns the total for non-padded tokens\n",
    "    y = target_token\n",
    "    y_pred = dec_result.logits\n",
    "    step_loss = self.loss(y, y_pred)\n",
    "\n",
    "    return step_loss, dec_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "96b7635c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T00:05:58.643774Z",
     "iopub.status.busy": "2021-12-17T00:05:58.642792Z",
     "iopub.status.idle": "2021-12-17T00:05:58.644438Z",
     "shell.execute_reply": "2021-12-17T00:05:58.644874Z",
     "shell.execute_reply.started": "2021-12-12T04:34:39.938197Z"
    },
    "papermill": {
     "duration": 0.273027,
     "end_time": "2021-12-17T00:05:58.645018",
     "exception": false,
     "start_time": "2021-12-17T00:05:58.371991",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "TrainTranslator._loop_step = _loop_step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2bade3",
   "metadata": {
    "papermill": {
     "duration": 0.2582,
     "end_time": "2021-12-17T00:05:59.161787",
     "exception": false,
     "start_time": "2021-12-17T00:05:58.903587",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Testing the training step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ebde4bbd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T00:05:59.889364Z",
     "iopub.status.busy": "2021-12-17T00:05:59.888432Z",
     "iopub.status.idle": "2021-12-17T00:05:59.892391Z",
     "shell.execute_reply": "2021-12-17T00:05:59.893446Z",
     "shell.execute_reply.started": "2021-12-12T04:34:43.843345Z"
    },
    "papermill": {
     "duration": 0.467291,
     "end_time": "2021-12-17T00:05:59.893637",
     "exception": false,
     "start_time": "2021-12-17T00:05:59.426346",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@tf.function(input_signature = [[tf.TensorSpec(dtype = tf.string,\n",
    "                                               shape = [None]),\n",
    "                                 tf.TensorSpec(dtype = tf.string,\n",
    "                                               shape = [None])]])\n",
    "\n",
    "def _tf_train_step(self, inputs):\n",
    "    return self._train_step(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "090505eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T00:06:00.512870Z",
     "iopub.status.busy": "2021-12-17T00:06:00.511961Z",
     "iopub.status.idle": "2021-12-17T00:06:00.514625Z",
     "shell.execute_reply": "2021-12-17T00:06:00.514164Z",
     "shell.execute_reply.started": "2021-12-12T04:34:48.818743Z"
    },
    "papermill": {
     "duration": 0.269026,
     "end_time": "2021-12-17T00:06:00.514745",
     "exception": false,
     "start_time": "2021-12-17T00:06:00.245719",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "TrainTranslator._tf_train_step = _tf_train_step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2fce2b4",
   "metadata": {
    "papermill": {
     "duration": 0.262544,
     "end_time": "2021-12-17T00:06:01.035264",
     "exception": false,
     "start_time": "2021-12-17T00:06:00.772720",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Training logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4eabc86e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T00:06:01.564109Z",
     "iopub.status.busy": "2021-12-17T00:06:01.563219Z",
     "iopub.status.idle": "2021-12-17T00:06:01.565070Z",
     "shell.execute_reply": "2021-12-17T00:06:01.565500Z",
     "shell.execute_reply.started": "2021-12-12T04:34:53.61668Z"
    },
    "papermill": {
     "duration": 0.270842,
     "end_time": "2021-12-17T00:06:01.565638",
     "exception": false,
     "start_time": "2021-12-17T00:06:01.294796",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BatchLogs(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "        self.logs = []\n",
    "\n",
    "    def on_train_batch_end(self, n, logs):\n",
    "        self.logs.append(logs[self.key])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82abee66",
   "metadata": {
    "papermill": {
     "duration": 0.259023,
     "end_time": "2021-12-17T00:06:02.084152",
     "exception": false,
     "start_time": "2021-12-17T00:06:01.825129",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## The translator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "316a1a8b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T00:06:02.615143Z",
     "iopub.status.busy": "2021-12-17T00:06:02.614183Z",
     "iopub.status.idle": "2021-12-17T00:06:02.615963Z",
     "shell.execute_reply": "2021-12-17T00:06:02.616385Z",
     "shell.execute_reply.started": "2021-12-12T04:34:57.869186Z"
    },
    "papermill": {
     "duration": 0.27437,
     "end_time": "2021-12-17T00:06:02.616528",
     "exception": false,
     "start_time": "2021-12-17T00:06:02.342158",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Translator(tf.Module):\n",
    "    def __init__(self, \n",
    "                 encoder, \n",
    "                 decoder, \n",
    "                 input_text_processor,\n",
    "                 output_text_processor):\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.input_text_processor = input_text_processor\n",
    "        self.output_text_processor = output_text_processor\n",
    "\n",
    "        self.output_token_string_from_index = (\n",
    "            tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "                vocabulary = output_text_processor.get_vocabulary(),\n",
    "                mask_token = \"\",\n",
    "                invert = True))\n",
    "\n",
    "        # the output should never generate padding, unknown, or start\n",
    "        index_from_string = tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "            vocabulary = output_text_processor.get_vocabulary(), \n",
    "            mask_token = \"\")\n",
    "        token_mask_ids = index_from_string(['', '[UNK]', '[START]']).numpy()\n",
    "\n",
    "        token_mask = np.zeros([index_from_string.vocabulary_size()], \n",
    "                           dtype=np.bool)\n",
    "        token_mask[np.array(token_mask_ids)] = True\n",
    "        self.token_mask = token_mask\n",
    "\n",
    "        self.start_token = index_from_string(tf.constant('[START]'))\n",
    "        self.end_token = index_from_string(tf.constant('[END]'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b231a943",
   "metadata": {
    "papermill": {
     "duration": 0.261998,
     "end_time": "2021-12-17T00:06:03.142692",
     "exception": false,
     "start_time": "2021-12-17T00:06:02.880694",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Convert token IDs to text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dcfd6e95",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T00:06:03.670434Z",
     "iopub.status.busy": "2021-12-17T00:06:03.669633Z",
     "iopub.status.idle": "2021-12-17T00:06:03.672577Z",
     "shell.execute_reply": "2021-12-17T00:06:03.672021Z",
     "shell.execute_reply.started": "2021-12-12T04:35:03.500779Z"
    },
    "papermill": {
     "duration": 0.269959,
     "end_time": "2021-12-17T00:06:03.672705",
     "exception": false,
     "start_time": "2021-12-17T00:06:03.402746",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tokens_to_text(self, result_tokens):\n",
    "    shape_checker = ShapeChecker()\n",
    "    shape_checker(result_tokens, (\"batch\", \"t\"))\n",
    "    result_text_tokens = self.output_token_string_from_index(result_tokens)\n",
    "    shape_checker(result_text_tokens, (\"batch\", \"t\"))\n",
    "\n",
    "    result_text = tf.strings.reduce_join(result_text_tokens,\n",
    "                                         axis=1, \n",
    "                                         separator=\" \")\n",
    "    shape_checker(result_text, (\"batch\"))\n",
    "\n",
    "    result_text = tf.strings.strip(result_text)\n",
    "    shape_checker(result_text, (\"batch\", ))\n",
    "    return result_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "73facca7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T00:06:04.194560Z",
     "iopub.status.busy": "2021-12-17T00:06:04.193659Z",
     "iopub.status.idle": "2021-12-17T00:06:04.195578Z",
     "shell.execute_reply": "2021-12-17T00:06:04.195983Z",
     "shell.execute_reply.started": "2021-12-12T04:35:07.327064Z"
    },
    "papermill": {
     "duration": 0.266577,
     "end_time": "2021-12-17T00:06:04.196123",
     "exception": false,
     "start_time": "2021-12-17T00:06:03.929546",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "Translator.tokens_to_text = tokens_to_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86824768",
   "metadata": {
    "papermill": {
     "duration": 0.346346,
     "end_time": "2021-12-17T00:06:04.801755",
     "exception": false,
     "start_time": "2021-12-17T00:06:04.455409",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Sampling from the decoder's predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a1c92b62",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T00:06:05.353014Z",
     "iopub.status.busy": "2021-12-17T00:06:05.351332Z",
     "iopub.status.idle": "2021-12-17T00:06:05.353632Z",
     "shell.execute_reply": "2021-12-17T00:06:05.354035Z",
     "shell.execute_reply.started": "2021-12-12T04:35:11.39648Z"
    },
    "papermill": {
     "duration": 0.288392,
     "end_time": "2021-12-17T00:06:05.354193",
     "exception": false,
     "start_time": "2021-12-17T00:06:05.065801",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sample(self, logits, temperature):\n",
    "    shape_checker = ShapeChecker()\n",
    "    # 't' is usually 1 here\n",
    "    shape_checker(logits, (\"batch\", \"t\", \"vocab\"))\n",
    "    shape_checker(self.token_mask, (\"vocab\", ))\n",
    "\n",
    "    token_mask = self.token_mask[tf.newaxis, tf.newaxis, :]\n",
    "    shape_checker(token_mask, (\"batch\", \"t\", \"vocab\"), \n",
    "                  broadcast = True)\n",
    "\n",
    "    # set the logits for all masked tokens to -inf, so they are never chosen\n",
    "    logits = tf.where(self.token_mask, -np.inf, logits)\n",
    "\n",
    "    if temperature == 0.0:\n",
    "        new_tokens = tf.argmax(logits, \n",
    "                               axis = -1)\n",
    "    else: \n",
    "        logits = tf.squeeze(logits, \n",
    "                            axis = 1)\n",
    "    new_tokens = tf.random.categorical(logits / temperature,\n",
    "                                       num_samples=1)\n",
    "\n",
    "    shape_checker(new_tokens, (\"batch\", \"t\"))\n",
    "\n",
    "    return new_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a74013f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T00:06:05.874225Z",
     "iopub.status.busy": "2021-12-17T00:06:05.873292Z",
     "iopub.status.idle": "2021-12-17T00:06:05.874908Z",
     "shell.execute_reply": "2021-12-17T00:06:05.875354Z",
     "shell.execute_reply.started": "2021-12-12T04:35:16.014422Z"
    },
    "papermill": {
     "duration": 0.265923,
     "end_time": "2021-12-17T00:06:05.875499",
     "exception": false,
     "start_time": "2021-12-17T00:06:05.609576",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "Translator.sample = sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc64cb48",
   "metadata": {
    "papermill": {
     "duration": 0.259312,
     "end_time": "2021-12-17T00:06:06.390714",
     "exception": false,
     "start_time": "2021-12-17T00:06:06.131402",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Implementing the translation loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a602ce30",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T00:06:06.941344Z",
     "iopub.status.busy": "2021-12-17T00:06:06.940565Z",
     "iopub.status.idle": "2021-12-17T00:06:06.943082Z",
     "shell.execute_reply": "2021-12-17T00:06:06.943503Z",
     "shell.execute_reply.started": "2021-12-12T04:35:20.113436Z"
    },
    "papermill": {
     "duration": 0.276058,
     "end_time": "2021-12-17T00:06:06.943659",
     "exception": false,
     "start_time": "2021-12-17T00:06:06.667601",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def translate_unrolled(self,\n",
    "                       input_text, \n",
    "                       *,\n",
    "                       max_length=50,\n",
    "                       return_attention=True,\n",
    "                       temperature=1.0):\n",
    "    batch_size = tf.shape(input_text)[0]\n",
    "    input_tokens = self.input_text_processor(input_text)\n",
    "    enc_output, enc_state = self.encoder(input_tokens)\n",
    "\n",
    "    dec_state = enc_state\n",
    "    new_tokens = tf.fill([batch_size, 1], self.start_token)\n",
    "\n",
    "    result_tokens = []\n",
    "    attention = []\n",
    "    done = tf.zeros([batch_size, 1], \n",
    "                    dtype = tf.bool)\n",
    "\n",
    "    for _ in range(max_length):\n",
    "        dec_input = DecoderInput(new_tokens = new_tokens,\n",
    "                                 enc_output = enc_output,\n",
    "                                 mask = (input_tokens != 0))\n",
    "\n",
    "        dec_result, dec_state = self.decoder(dec_input, \n",
    "                                             state = dec_state)\n",
    "\n",
    "        attention.append(dec_result.attention_weights)\n",
    "\n",
    "        new_tokens = self.sample(dec_result.logits, \n",
    "                                 temperature)\n",
    "\n",
    "        # if a sequence produces an 'end_token', set it 'done'\n",
    "        done = done | (new_tokens == self.end_token)\n",
    "        # once a sequence is done it only produces 0-padding\n",
    "        new_tokens = tf.where(done, \n",
    "                              tf.constant(0, dtype = tf.int64), \n",
    "                              new_tokens)\n",
    "\n",
    "        # collect the generated tokens\n",
    "        result_tokens.append(new_tokens)\n",
    "\n",
    "        if tf.executing_eagerly() and tf.reduce_all(done):\n",
    "            break\n",
    "\n",
    "    # convert the list of generates token ids to a list of strings\n",
    "    result_tokens = tf.concat(result_tokens,\n",
    "                              axis = -1)\n",
    "    result_text = self.tokens_to_text(result_tokens)\n",
    "\n",
    "    if return_attention:\n",
    "        attention_stack = tf.concat(attention, \n",
    "                                    axis = 1)\n",
    "        return {\"text\": result_text, \n",
    "                \"attention\": attention_stack}\n",
    "    else:\n",
    "        return {\"text\": result_text}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cbd78b97",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T00:06:07.463150Z",
     "iopub.status.busy": "2021-12-17T00:06:07.462213Z",
     "iopub.status.idle": "2021-12-17T00:06:07.463803Z",
     "shell.execute_reply": "2021-12-17T00:06:07.464232Z",
     "shell.execute_reply.started": "2021-12-12T04:35:25.715098Z"
    },
    "papermill": {
     "duration": 0.26417,
     "end_time": "2021-12-17T00:06:07.464377",
     "exception": false,
     "start_time": "2021-12-17T00:06:07.200207",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "Translator.translate = translate_unrolled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6f274951",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T00:06:07.988450Z",
     "iopub.status.busy": "2021-12-17T00:06:07.987387Z",
     "iopub.status.idle": "2021-12-17T00:06:07.989206Z",
     "shell.execute_reply": "2021-12-17T00:06:07.989711Z",
     "shell.execute_reply.started": "2021-12-12T04:35:29.275049Z"
    },
    "papermill": {
     "duration": 0.270023,
     "end_time": "2021-12-17T00:06:07.989860",
     "exception": false,
     "start_time": "2021-12-17T00:06:07.719837",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@tf.function(input_signature = [tf.TensorSpec(dtype = tf.string, \n",
    "                                              shape = [None])])\n",
    "def tf_translate(self, input_text):\n",
    "    return self.translate(input_text)\n",
    "\n",
    "Translator.tf_translate = tf_translate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1fb1ab",
   "metadata": {
    "papermill": {
     "duration": 0.260895,
     "end_time": "2021-12-17T00:06:08.506206",
     "exception": false,
     "start_time": "2021-12-17T00:06:08.245311",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Build and train a translator model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f4dab4",
   "metadata": {
    "papermill": {
     "duration": 0.260296,
     "end_time": "2021-12-17T00:06:09.022664",
     "exception": false,
     "start_time": "2021-12-17T00:06:08.762368",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Preprocess the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4c111481",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T00:06:09.555203Z",
     "iopub.status.busy": "2021-12-17T00:06:09.554028Z",
     "iopub.status.idle": "2021-12-17T00:06:09.555967Z",
     "shell.execute_reply": "2021-12-17T00:06:09.556417Z",
     "shell.execute_reply.started": "2021-12-12T04:35:32.961197Z"
    },
    "papermill": {
     "duration": 0.273003,
     "end_time": "2021-12-17T00:06:09.556566",
     "exception": false,
     "start_time": "2021-12-17T00:06:09.283563",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_vocab_size = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "eacc6423",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T00:06:10.190057Z",
     "iopub.status.busy": "2021-12-17T00:06:10.189161Z",
     "iopub.status.idle": "2021-12-17T00:06:13.260539Z",
     "shell.execute_reply": "2021-12-17T00:06:13.261053Z",
     "shell.execute_reply.started": "2021-12-12T04:35:36.764549Z"
    },
    "papermill": {
     "duration": 3.340352,
     "end_time": "2021-12-17T00:06:13.261242",
     "exception": false,
     "start_time": "2021-12-17T00:06:09.920890",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_text_processor = preprocessing.TextVectorization(standardize = tf_lower_and_split_punct,\n",
    "                                                       max_tokens = max_vocab_size)\n",
    "input_text_processor.adapt(train_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "35afd40c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T00:06:13.880413Z",
     "iopub.status.busy": "2021-12-17T00:06:13.879608Z",
     "iopub.status.idle": "2021-12-17T00:06:16.781028Z",
     "shell.execute_reply": "2021-12-17T00:06:16.780514Z",
     "shell.execute_reply.started": "2021-12-12T04:35:40.264572Z"
    },
    "papermill": {
     "duration": 3.167492,
     "end_time": "2021-12-17T00:06:16.781153",
     "exception": false,
     "start_time": "2021-12-17T00:06:13.613661",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_text_processor = preprocessing.TextVectorization(standardize = tf_lower_and_split_punct,\n",
    "                                                        max_tokens = max_vocab_size)\n",
    "output_text_processor.adapt(train_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f56441",
   "metadata": {
    "papermill": {
     "duration": 0.256573,
     "end_time": "2021-12-17T00:06:17.297434",
     "exception": false,
     "start_time": "2021-12-17T00:06:17.040861",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Compile and train a translator model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cda921dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T00:06:17.824148Z",
     "iopub.status.busy": "2021-12-17T00:06:17.823230Z",
     "iopub.status.idle": "2021-12-17T00:06:17.825576Z",
     "shell.execute_reply": "2021-12-17T00:06:17.825024Z",
     "shell.execute_reply.started": "2021-12-12T04:35:43.715188Z"
    },
    "papermill": {
     "duration": 0.268394,
     "end_time": "2021-12-17T00:06:17.825694",
     "exception": false,
     "start_time": "2021-12-17T00:06:17.557300",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "embedding_dim = 256\n",
    "units = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "258efacd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T00:06:18.354155Z",
     "iopub.status.busy": "2021-12-17T00:06:18.353329Z",
     "iopub.status.idle": "2021-12-17T00:06:18.378855Z",
     "shell.execute_reply": "2021-12-17T00:06:18.378378Z",
     "shell.execute_reply.started": "2021-12-12T04:35:47.783243Z"
    },
    "papermill": {
     "duration": 0.292384,
     "end_time": "2021-12-17T00:06:18.379000",
     "exception": false,
     "start_time": "2021-12-17T00:06:18.086616",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_translator = TrainTranslator(embedding_dim, \n",
    "                                   units,\n",
    "                                   input_text_processor = input_text_processor,\n",
    "                                   output_text_processor = output_text_processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b1fdf912",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T00:06:18.912101Z",
     "iopub.status.busy": "2021-12-17T00:06:18.911210Z",
     "iopub.status.idle": "2021-12-17T00:06:18.918476Z",
     "shell.execute_reply": "2021-12-17T00:06:18.917925Z",
     "shell.execute_reply.started": "2021-12-12T04:35:51.702581Z"
    },
    "papermill": {
     "duration": 0.276749,
     "end_time": "2021-12-17T00:06:18.918604",
     "exception": false,
     "start_time": "2021-12-17T00:06:18.641855",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_translator.compile(loss = MaskedLoss(),\n",
    "                         optimizer = tf.optimizers.Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f3df85cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T00:06:19.438768Z",
     "iopub.status.busy": "2021-12-17T00:06:19.437892Z",
     "iopub.status.idle": "2021-12-17T00:06:19.439785Z",
     "shell.execute_reply": "2021-12-17T00:06:19.440216Z",
     "shell.execute_reply.started": "2021-12-12T04:35:55.048144Z"
    },
    "papermill": {
     "duration": 0.265907,
     "end_time": "2021-12-17T00:06:19.440373",
     "exception": false,
     "start_time": "2021-12-17T00:06:19.174466",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_loss = BatchLogs(\"batch_loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3355ba3d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T00:06:19.958841Z",
     "iopub.status.busy": "2021-12-17T00:06:19.958028Z",
     "iopub.status.idle": "2021-12-17T01:19:21.466672Z",
     "shell.execute_reply": "2021-12-17T01:19:21.464332Z",
     "shell.execute_reply.started": "2021-12-12T04:35:58.797301Z"
    },
    "papermill": {
     "duration": 4381.771162,
     "end_time": "2021-12-17T01:19:21.466848",
     "exception": false,
     "start_time": "2021-12-17T00:06:19.695686",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "704/704 [==============================] - 1457s 2s/step - batch_loss: 2.7269\n",
      "Epoch 2/3\n",
      "704/704 [==============================] - 1433s 2s/step - batch_loss: 1.3056\n",
      "Epoch 3/3\n",
      "704/704 [==============================] - 1450s 2s/step - batch_loss: 0.8927\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f842d152550>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_translator.fit(dataset, \n",
    "                     epochs = 3,\n",
    "                     callbacks = [batch_loss])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79f6123",
   "metadata": {
    "papermill": {
     "duration": 0.79612,
     "end_time": "2021-12-17T01:19:23.056154",
     "exception": false,
     "start_time": "2021-12-17T01:19:22.260034",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Use the trained model to create a translator object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "826e23f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T01:19:24.702552Z",
     "iopub.status.busy": "2021-12-17T01:19:24.701656Z",
     "iopub.status.idle": "2021-12-17T01:19:24.836817Z",
     "shell.execute_reply": "2021-12-17T01:19:24.836117Z",
     "shell.execute_reply.started": "2021-12-12T04:36:34.994918Z"
    },
    "papermill": {
     "duration": 0.932807,
     "end_time": "2021-12-17T01:19:24.836972",
     "exception": false,
     "start_time": "2021-12-17T01:19:23.904165",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "translator = Translator(encoder = train_translator.encoder,\n",
    "                        decoder = train_translator.decoder,\n",
    "                        input_text_processor = input_text_processor,\n",
    "                        output_text_processor = output_text_processor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df4d33d",
   "metadata": {
    "papermill": {
     "duration": 0.797629,
     "end_time": "2021-12-17T01:19:26.430776",
     "exception": false,
     "start_time": "2021-12-17T01:19:25.633147",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Evaluate the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6be044",
   "metadata": {
    "papermill": {
     "duration": 0.804672,
     "end_time": "2021-12-17T01:19:28.059577",
     "exception": false,
     "start_time": "2021-12-17T01:19:27.254905",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Evaluate the accuracy of the model's translations by computing its BLEU (Bilingual Evaluation Understudy) score on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3332599e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T01:19:29.658534Z",
     "iopub.status.busy": "2021-12-17T01:19:29.657619Z",
     "iopub.status.idle": "2021-12-17T01:19:29.659449Z",
     "shell.execute_reply": "2021-12-17T01:19:29.659853Z",
     "shell.execute_reply.started": "2021-12-14T12:51:25.247625Z"
    },
    "papermill": {
     "duration": 0.802099,
     "end_time": "2021-12-17T01:19:29.659989",
     "exception": false,
     "start_time": "2021-12-17T01:19:28.857890",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def StandardizeTarget(target):\n",
    "    # split accented characters\n",
    "    target = tf_text.normalize_utf8(target,\n",
    "                                    \"NFKD\")\n",
    "    target = tf.strings.lower(target)\n",
    "    \n",
    "    # keep spaces, a-z, and select punctuation\n",
    "    target = tf.strings.regex_replace(target,\n",
    "                                      \"[^ a-z.?!,¿]\",\n",
    "                                      \"\")\n",
    "    \n",
    "    # add spaces around punctuation\n",
    "    target = tf.strings.regex_replace(target,\n",
    "                                      \"[.?!,¿]\",\n",
    "                                      r\" \\0 \")\n",
    "    \n",
    "    # strip whitespace\n",
    "    target = tf.strings.strip(target)\n",
    "    \n",
    "    # convert the string tensor to a regular string\n",
    "    target = target.numpy().decode()\n",
    "    \n",
    "    return target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a84d1ac8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T01:19:32.056631Z",
     "iopub.status.busy": "2021-12-17T01:19:32.055689Z",
     "iopub.status.idle": "2021-12-17T01:19:32.057487Z",
     "shell.execute_reply": "2021-12-17T01:19:32.057895Z",
     "shell.execute_reply.started": "2021-12-14T12:51:06.020815Z"
    },
    "papermill": {
     "duration": 1.577462,
     "end_time": "2021-12-17T01:19:32.058032",
     "exception": false,
     "start_time": "2021-12-17T01:19:30.480570",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def StandardizeListOfTargets(list_of_targets):\n",
    "    return [StandardizeTarget(target) for target in list_of_targets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ba92de75",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T01:19:33.663841Z",
     "iopub.status.busy": "2021-12-17T01:19:33.662960Z",
     "iopub.status.idle": "2021-12-17T01:19:33.664840Z",
     "shell.execute_reply": "2021-12-17T01:19:33.665267Z",
     "shell.execute_reply.started": "2021-12-14T12:51:09.129194Z"
    },
    "papermill": {
     "duration": 0.810652,
     "end_time": "2021-12-17T01:19:33.665417",
     "exception": false,
     "start_time": "2021-12-17T01:19:32.854765",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def TokenizeListOfTargets(list_of_targets):\n",
    "    return [target.split(\" \") for target in list_of_targets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9ee9d786",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T01:19:35.273006Z",
     "iopub.status.busy": "2021-12-17T01:19:35.272212Z",
     "iopub.status.idle": "2021-12-17T01:20:43.724118Z",
     "shell.execute_reply": "2021-12-17T01:20:43.723596Z",
     "shell.execute_reply.started": "2021-12-12T04:36:47.165479Z"
    },
    "papermill": {
     "duration": 69.271815,
     "end_time": "2021-12-17T01:20:43.724279",
     "exception": false,
     "start_time": "2021-12-17T01:19:34.452464",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# make predictions on the test set\n",
    "\n",
    "input_text = tf.constant(test_inputs)\n",
    "raw_predictions = translator.translate(input_text = input_text)\n",
    "predictions = []\n",
    "\n",
    "for i in range(len(input_text)):\n",
    "    predictions.append(raw_predictions[\"text\"][i].numpy().decode())\n",
    "\n",
    "tokenized_predictions = list(map(lambda x: x.split(), predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fffa445d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T01:20:45.394673Z",
     "iopub.status.busy": "2021-12-17T01:20:45.389598Z",
     "iopub.status.idle": "2021-12-17T01:20:46.051220Z",
     "shell.execute_reply": "2021-12-17T01:20:46.050717Z",
     "shell.execute_reply.started": "2021-12-14T12:51:31.057794Z"
    },
    "papermill": {
     "duration": 1.468563,
     "end_time": "2021-12-17T01:20:46.051363",
     "exception": false,
     "start_time": "2021-12-17T01:20:44.582800",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# collate the targets into a list of list of list of tokens\n",
    "\n",
    "# make a mapping from each input text to all target texts which it corresponds to\n",
    "input_to_target = dict()\n",
    "\n",
    "for input_text, target_text in list(zip(test_inputs, test_targets)):\n",
    "    if input_text not in input_to_target.keys():\n",
    "        input_to_target[input_text] = [target_text]\n",
    "    else:\n",
    "        input_to_target[input_text] = input_to_target[input_text] + [target_text]\n",
    "\n",
    "# cluster together the alternative target texts corresponding to each input text\n",
    "clustered_targets = list(map(input_to_target.get, test_inputs))\n",
    "\n",
    "# standardize the target text\n",
    "standardized_targets = [StandardizeListOfTargets(list_of_targets) for list_of_targets in clustered_targets]\n",
    "\n",
    "# tokenize the target text\n",
    "tokenized_targets = [TokenizeListOfTargets(list_of_targets) for list_of_targets in standardized_targets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e82fe4a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T01:20:47.882763Z",
     "iopub.status.busy": "2021-12-17T01:20:47.881938Z",
     "iopub.status.idle": "2021-12-17T01:20:48.361998Z",
     "shell.execute_reply": "2021-12-17T01:20:48.362768Z",
     "shell.execute_reply.started": "2021-12-12T04:37:00.929102Z"
    },
    "papermill": {
     "duration": 1.480845,
     "end_time": "2021-12-17T01:20:48.362976",
     "exception": false,
     "start_time": "2021-12-17T01:20:46.882131",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score for the final model: 0.2322011280125518\n"
     ]
    }
   ],
   "source": [
    "# obtain the BLEU score across all predictions\n",
    "\n",
    "bleu_score = corpus_bleu(list_of_references = tokenized_targets,\n",
    "                         hypotheses = tokenized_predictions)\n",
    "\n",
    "print(f\"BLEU score for the final model: {bleu_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "029ad9e0",
   "metadata": {
    "papermill": {
     "duration": 0.809783,
     "end_time": "2021-12-17T01:20:50.016632",
     "exception": false,
     "start_time": "2021-12-17T01:20:49.206849",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Export the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe79e78",
   "metadata": {
    "papermill": {
     "duration": 0.807001,
     "end_time": "2021-12-17T01:20:51.617435",
     "exception": false,
     "start_time": "2021-12-17T01:20:50.810434",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Save the architecture and weights associated with the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f29efba0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T01:20:53.236074Z",
     "iopub.status.busy": "2021-12-17T01:20:53.235236Z",
     "iopub.status.idle": "2021-12-17T01:21:15.162265Z",
     "shell.execute_reply": "2021-12-17T01:21:15.162694Z",
     "shell.execute_reply.started": "2021-12-12T04:37:09.555312Z"
    },
    "papermill": {
     "duration": 22.735253,
     "end_time": "2021-12-17T01:21:15.162863",
     "exception": false,
     "start_time": "2021-12-17T01:20:52.427610",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-17 01:21:08.550804: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    }
   ],
   "source": [
    "tf.saved_model.save(translator, \n",
    "                    \"translator\",\n",
    "                    signatures = {\"serving_default\": translator.tf_translate})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 4651.75113,
   "end_time": "2021-12-17T01:21:19.654574",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-12-17T00:03:47.903444",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
